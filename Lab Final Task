#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <cctype>
#include <algorithm>

// Token types
enum class TokenType {
    INTEGER,
    FLOAT,
    IDENTIFIER,
    KEYWORD,
    OPERATOR,
    DELIMITER,
    COMMENT,
    STRING_LITERAL,
    UNKNOWN
};

// Token structure
struct Token {
    TokenType type;
    std::string lexeme;
};

// Function to classify token types
TokenType classifyToken(const std::string& token) {
    // Check if it's an integer
    bool isInteger = true;
    for (char c : token) {
        if (!isdigit(c)) {
            isInteger = false;
            break;
        }
    }
    if (isInteger) return TokenType::INTEGER;

    // Check if it's a floating point number
    bool isFloat = true;
    bool hasDot = false;
    for (char c : token) {
        if (!isdigit(c)) {
            if (c == '.' && !hasDot) {
                hasDot = true;
            } else {
                isFloat = false;
                break;
            }
        }
    }
    if (isFloat) return TokenType::FLOAT;

    // Check if it's an identifier
    if (isalpha(token[0]) || token[0] == '_') {
        bool valid = true;
        for (char c : token) {
            if (!isalnum(c) && c != '_') {
                valid = false;
                break;
            }
        }
        if (valid) return TokenType::IDENTIFIER;
    }

    // Check if it's a keyword
    std::vector<std::string> keywords = {"if", "else", "while", "for", "int", "float", "double", "char", "return", "void"};
    if (std::find(keywords.begin(), keywords.end(), token) != keywords.end()) return TokenType::KEYWORD;

    // Check if it's an operator
    std::string operators = "+-*/=><&|^%!";
    if (operators.find(token) != std::string::npos) return TokenType::OPERATOR;

    // Check if it's a delimiter
    std::string delimiters = ",;(){}[]";
    if (delimiters.find(token) != std::string::npos) return TokenType::DELIMITER;

    // Check if it's a comment
    if (token.size() >= 2 && token.substr(0, 2) == "//") return TokenType::COMMENT;
    if (token.size() >= 2 && token.substr(0, 2) == "/*" && token.back() == '*' && token[token.size() - 2] == '/') return TokenType::COMMENT;

    // Check if it's a string literal
    if (token.size() >= 2 && ((token.front() == '"' && token.back() == '"') || (token.front() == '\'' && token.back() == '\''))) return TokenType::STRING_LITERAL;

    // If none of the above, it's unknown
    return TokenType::UNKNOWN;
}

// Function to tokenize input text
std::vector<Token> tokenize(const std::string& input) {
    std::vector<Token> tokens;
    std::string currentToken;

    bool inComment = false;

    for (size_t i = 0; i < input.size(); ++i) {
        char c = input[i];

        // Check if in a comment
        if (inComment) {
            if (c == '*' && i < input.size() - 1 && input[i + 1] == '/') {
                inComment = false;
                ++i; // Skip '/'
            }
            continue;
        }

        // Check if the character is a delimiter or in a comment
        if (isspace(c) || c == ',' || c == ';' || c == '(' || c == ')' || c == '{' || c == '}' || c == '[' || c == ']' || (c == '/' && i < input.size() - 1 && input[i + 1] == '/')) {
            if (!currentToken.empty()) {
                tokens.push_back({classifyToken(currentToken), currentToken});
                currentToken.clear();
            }
            if (!isspace(c) && c != '/') {
                tokens.push_back({classifyToken(std::string(1, c)), std::string(1, c)});
            }
            if (c == '/' && i < input.size() - 1 && input[i + 1] == '/') {
                break; // Ignore the rest of the line for single-line comments
            }
        }
        // Check if the character is an operator or start of a comment
        else if (c == '+' || c == '-' || c == '*' || c == '=' || c == '<' || c == '>' || c == '&' || c == '|' || c == '^' || c == '%' || c == '!') {
            if (!currentToken.empty()) {
                tokens.push_back({classifyToken(currentToken), currentToken});
                currentToken.clear();
            }
            tokens.push_back({classifyToken(std::string(1, c)), std::string(1, c)});
            if (c == '/' && i < input.size() - 1 && input[i + 1] == '*') {
                inComment = true; // Start of a multi-line comment
                ++i; // Skip '*'
            }
        }
        // Otherwise, add character to the current token
        else {
            currentToken += c;
        }
    }

    // Add the last token if it exists
    if (!currentToken.empty()) {
        tokens.push_back({classifyToken(currentToken), currentToken});
    }

    return tokens;
}

int main() {
    std::ifstream inputFile("Lexeme.txt");
    if (!inputFile.is_open()) {
        std::cerr << "Failed to open file." << std::endl;
        return 1;
    }

    std::string input;
    std::string line;
    while (std::getline(inputFile, line)) {
        input += line + '\n'; // Add newline character for each line
    }
    inputFile.close();

    // Tokenize input
    std::vector<Token> tokens = tokenize(input);

    // Print tokens with lexemes
    std::cout << "Tokens:" << std::endl;
    for (const auto& token : tokens) {
        std::string tokenType;
        switch (token.type) {
            case TokenType::INTEGER:
                tokenType = "INTEGER";
                break;
            case TokenType::FLOAT:
                tokenType = "FLOAT";
                break;
            case TokenType::IDENTIFIER:
                tokenType = "IDENTIFIER";
                break;
            case TokenType::KEYWORD:
                tokenType = "KEYWORD";
                break;
            case TokenType::OPERATOR:
                tokenType = "OPERATOR";
                break;
            case TokenType::DELIMITER:
                tokenType = "DELIMITER";
                break;
            case TokenType::COMMENT:
                tokenType = "COMMENT";
                break;
            case TokenType::STRING_LITERAL:
                tokenType = "STRING_LITERAL";
                break;
            case TokenType::UNKNOWN:
                tokenType = "UNKNOWN";
                break;
        }
        std::cout << "Token: " << tokenType << ", Lexeme: " << token.lexeme << std::endl;
    }

    return 0;
}
